{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model  Train Accuracy  Test Accuracy  \\\n",
      "0      Decision Tree          0.9792         0.9875   \n",
      "1  Gradient Boosting          1.0000         0.9875   \n",
      "\n",
      "   Cross-Validation Accuracy  Cross-Validation STD  \n",
      "0                     0.9375                0.0373  \n",
      "1                     0.9800                   NaN  \n",
      "\n",
      "Detailed Classification Report for Gradient Boosting:\n",
      "  Precision: {'Class 0': 0.97, 'Class 1': 1.0}\n",
      "  Recall: {'Class 0': 1.0, 'Class 1': 0.98}\n",
      "  F1-Score: {'Class 0': 0.98, 'Class 1': 0.99}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Store model results in a list of dictionaries\n",
    "model_results = []\n",
    "\n",
    "# ===== DECISION TREE =====\n",
    "# Add Decision Tree After Overfitting Analysis Results\n",
    "model_results.append({\n",
    "    \"Model\": \"Decision Tree\",\n",
    "    \"Train Accuracy\": 0.9792,\n",
    "    \"Test Accuracy\": 0.9875,\n",
    "    \"Cross-Validation Accuracy\": 0.9375,\n",
    "    \"Cross-Validation STD\": 0.0373,\n",
    "    \"Classification Report\": None  # You can add if needed\n",
    "})\n",
    "\n",
    "# ===== GRADIENT BOOSTING =====\n",
    "# Add Gradient Boosting Results\n",
    "model_results.append({\n",
    "    \"Model\": \"Gradient Boosting\",\n",
    "    \"Train Accuracy\": 1.0,\n",
    "    \"Test Accuracy\": 0.9875,\n",
    "    \"Cross-Validation Accuracy\": 0.9800,\n",
    "    \"Cross-Validation STD\": None,  # Not provided\n",
    "    \"Classification Report\": {\n",
    "        \"Precision\": {\"Class 0\": 0.97, \"Class 1\": 1.00},\n",
    "        \"Recall\": {\"Class 0\": 1.00, \"Class 1\": 0.98},\n",
    "        \"F1-Score\": {\"Class 0\": 0.98, \"Class 1\": 0.99},\n",
    "    }\n",
    "})\n",
    "\n",
    "# ===== OUTPUT RESULTS =====\n",
    "\n",
    "# Convert results into a DataFrame for tabular comparison\n",
    "comparison_df = pd.DataFrame(model_results).drop(columns=[\"Classification Report\"])  # Drop detailed report for simplicity\n",
    "\n",
    "# Save results to CSV for external analysis\n",
    "comparison_df.to_csv(\"model_comparison_results.csv\", index=False)\n",
    "\n",
    "# Display the comparison\n",
    "print(comparison_df)\n",
    "\n",
    "# ===== OPTIONAL: DISPLAY CLASSIFICATION REPORTS =====\n",
    "# Show detailed classification reports for each model\n",
    "for result in model_results:\n",
    "    if result[\"Classification Report\"]:\n",
    "        print(f\"\\nDetailed Classification Report for {result['Model']}:\")\n",
    "        for cls, metrics in result[\"Classification Report\"].items():\n",
    "            print(f\"  {cls}: {metrics}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         Naive Bayes and Logistic Regression Comparison:\n",
      "                 Model  Test Accuracy  Cross-Validation Accuracy  \\\n",
      "0          Naive Bayes         0.9375                      0.940   \n",
      "1  Logistic Regression         0.9875                      0.975   \n",
      "\n",
      "   Cross-Validation STD  \n",
      "0                0.0267  \n",
      "1                0.0159  \n",
      "\n",
      "Detailed Classification Report for Naive Bayes:\n",
      "  Precision: {'Class 0': 0.9, 'Class 1': 0.96}\n",
      "  Recall: {'Class 0': 0.93, 'Class 1': 0.94}\n",
      "  F1-Score: {'Class 0': 0.91, 'Class 1': 0.95}\n",
      "\n",
      "Detailed Classification Report for Logistic Regression:\n",
      "  Precision: {'Class 0': 0.93, 'Class 1': 0.98}\n",
      "  Recall: {'Class 0': 0.96, 'Class 1': 0.96}\n",
      "  F1-Score: {'Class 0': 0.95, 'Class 1': 0.97}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create separate lists for Naive Bayes and Logistic Regression results\n",
    "nb_lr_results = []\n",
    "\n",
    "# ===== NAIVE BAYES =====\n",
    "nb_lr_results.append({\n",
    "    \"Model\": \"Naive Bayes\",\n",
    "    \"Test Accuracy\": 0.9375,\n",
    "    \"Cross-Validation Accuracy\": 0.9400,\n",
    "    \"Cross-Validation STD\": 0.0267,\n",
    "    \"Classification Report\": {\n",
    "        \"Precision\": {\"Class 0\": 0.90, \"Class 1\": 0.96},\n",
    "        \"Recall\": {\"Class 0\": 0.93, \"Class 1\": 0.94},\n",
    "        \"F1-Score\": {\"Class 0\": 0.91, \"Class 1\": 0.95},\n",
    "    }\n",
    "})\n",
    "\n",
    "# ===== LOGISTIC REGRESSION =====\n",
    "nb_lr_results.append({\n",
    "    \"Model\": \"Logistic Regression\",\n",
    "    \"Test Accuracy\": 0.9875,\n",
    "    \"Cross-Validation Accuracy\": 0.9750,\n",
    "    \"Cross-Validation STD\": 0.0159,\n",
    "    \"Classification Report\": {\n",
    "        \"Precision\": {\"Class 0\": 0.93, \"Class 1\": 0.98},\n",
    "        \"Recall\": {\"Class 0\": 0.96, \"Class 1\": 0.96},\n",
    "        \"F1-Score\": {\"Class 0\": 0.95, \"Class 1\": 0.97},\n",
    "    }\n",
    "})\n",
    "\n",
    "# ===== OUTPUT RESULTS =====\n",
    "\n",
    "# Convert results into a DataFrame for tabular comparison\n",
    "nb_lr_comparison_df = pd.DataFrame(nb_lr_results).drop(columns=[\"Classification Report\"])\n",
    "\n",
    "# Save results to CSV for external analysis\n",
    "nb_lr_comparison_df.to_csv(\"nb_lr_model_comparison.csv\", index=False)\n",
    "\n",
    "# Display the comparison\n",
    "print(\"\\n         Naive Bayes and Logistic Regression Comparison:\")\n",
    "print(nb_lr_comparison_df)\n",
    "\n",
    "# ===== OPTIONAL: DETAILED CLASSIFICATION REPORTS =====\n",
    "# Show detailed classification reports for Naive Bayes and Logistic Regression\n",
    "for result in nb_lr_results:\n",
    "    if result[\"Classification Report\"]:\n",
    "        print(f\"\\nDetailed Classification Report for {result['Model']}:\")\n",
    "        for metric, classes in result[\"Classification Report\"].items():\n",
    "            print(f\"  {metric}: {classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
